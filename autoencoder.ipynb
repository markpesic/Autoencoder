{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nfrom sklearn import metrics\nfrom sklearn import decomposition\nfrom sklearn import manifold\nimport matplotlib.pyplot as plt\n\nimport copy\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 1\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nROOT = '.data'\ntrain_data = datasets.MNIST(root = ROOT, \n                            train = True, \n                            download = True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = train_data.data.float().mean()\nstd = train_data.data.float().std()\n\nprint(mean)\nprint(std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Calculated mean: {mean}')\nprint(f'Calculated std: {std}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = transforms.Compose([\n                            #transforms.RandomRotation(5, fill=(0,)),\n                            #transforms.RandomCrop(28, padding = 2),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=[0.5], std=[0.5])\n                                      ])\n\ntest_transforms = transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize(mean=(0.5), std=(0.5))\n                                     ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = datasets.MNIST(root = ROOT, \n                            train = True, \n                            download = True, \n                            transform = train_transforms)\n\ntest_data = datasets.MNIST(root = ROOT, \n                           train = False, \n                           download = True, \n                           transform = test_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.data.float().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_images(images):\n\n    n_images = len(images)\n\n    rows = int(np.sqrt(n_images))\n    cols = int(np.sqrt(n_images))\n\n    fig = plt.figure()\n    for i in range(rows*cols):\n        ax = fig.add_subplot(rows, cols, i+1)\n        ax.imshow(images[i].view(28, 28).cpu().numpy())\n        ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VALID_RATIO = 0.9\n\nn_train_examples = int(len(train_data) * VALID_RATIO)\nn_valid_examples = len(train_data) - n_train_examples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, valid_data = data.random_split(train_data, \n                                           [n_train_examples, n_valid_examples])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_IMAGES = 25\n\nimages = [image for image, label in [train_data[i] for i in range(N_IMAGES)]] \n\nplot_images(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of training examples: {len(train_data)}')\nprint(f'Number of validation examples: {len(valid_data)}')\nprint(f'Number of testing examples: {len(test_data)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_data = copy.deepcopy(valid_data)\nvalid_data.dataset.transform = test_transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_IMAGES = 25\n\nimages = [image for image, label in [valid_data[i] for i in range(N_IMAGES)]] \n\nplot_images(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 256\n\ntrain_iterator = data.DataLoader(train_data, \n                                 shuffle = True, \n                                 batch_size = BATCH_SIZE)\n\nvalid_iterator = data.DataLoader(valid_data, \n                                 batch_size = BATCH_SIZE)\n\ntest_iterator = data.DataLoader(test_data, \n                                batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, labels = iter(train_iterator).next()\nprint(images)\nprint(images.max())\nprint(images.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = {\n    \"embedding_size\":784,\n    \"hidden_size\":500,\n    \"hidden_size1\":256,\n    \"hidden_size2\":128,\n    \"hidden_size3\":64,\n    \"hidden_size4\":32\n}\n\nconfigVAE = {\n    \"embedding_size\":784,\n    \"hidden_size\":400,\n    \"hidden_size1\":4,\n    \"hidden_size2\":2\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_img(x, size_x=28):\n    x = 0.5 * (x + 1)\n    x = x.view(x.size(0), size_x, size_x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images(in_, out, n=1, size_x=28):\n    for N in range(n):\n        if in_ is not None:\n            in_pic = to_img(in_.cpu().data)\n            plt.figure(figsize=(18, 6))\n            for i in range(4):\n                plt.subplot(1,4,i+1)\n                plt.imshow(in_pic[i+4*N])\n                plt.axis('off')\n        out_pic = to_img(out.cpu().data)\n        plt.figure(figsize=(18, 6))\n        for i in range(4):\n            plt.subplot(1,4,i+1)\n            plt.imshow(out_pic[i+4*N])\n            plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DENOISE AUTOECODER"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AE(nn.Module):\n    def __init__(self, config):\n        super(AE, self).__init__()\n        self.Encoder = nn.Sequential(nn.Linear(config['embedding_size'], config['hidden_size']), nn.ReLU(inplace=True))\n        self.Decoder = nn.Sequential(nn.Linear(config['hidden_size'], config['embedding_size']), nn.LeakyReLU(0.8))\n        \n    def forward(self, x):\n        z = self.Encoder(x)\n        out = self.Decoder(z)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def criterion(model, images, y_pred, reg_param):\n    loss = nn.MSELoss()\n    loss1 = loss(y_pred, images)\n\n    return loss1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_func(optimizer , criterion, train_data, model, device, reg_param=0.001):\n    model.train()\n    \n    loss_train = []\n    model.to(device)\n    do = nn.Dropout()\n    for (x,_) in train_data:\n        x = x.to(device)\n        x = x.view(x.shape[0], -1)\n        \n        noise = do(torch.ones(x.shape)).to(device)\n        x_bad = (x * noise).to(device)\n        \n        out = model(x_bad)\n        \n        loss = criterion(model, x, out, reg_param)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        optimizer.zero_grad()\n        \n        loss_train.append(loss.item())\n        \n    return loss_train\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def valid_func(criterion, valid_data, model, device, reg_param=0.001):\n    model.eval()\n    \n    valid_loss = []\n    model.to(device)\n    do = nn.Dropout()\n    with torch.no_grad():\n        for (x,_) in valid_data:\n\n            x = x.to(device)\n            x = x.view(x.shape[0], -1)\n            \n            noise = do(torch.ones(x.shape)).to(device)\n            x_bad = (x * noise).to(device)\n\n            out = model(x_bad)\n\n            loss = criterion(model, x, out, reg_param)\n\n            valid_loss.append(loss.item())\n        \n    return valid_loss\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nlearning_rate = 1e-3\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = AE(config)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nmodel_children = list(model.children())\n\nfor epoch in range(epochs):\n    loss_train = train_func(optimizer, criterion, train_iterator, model, device)\n    print(\"Epoch: {} || Loss: {}\".format(epoch, (np.sum(loss_train)/len(loss_train))))\n    valid_loss = valid_func(criterion, valid_iterator, model, device)\n    print(\"Epoch: {} || Validation Loss: {}\".format(epoch, (np.sum(valid_loss)/len(valid_loss))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pred_fn(model, test_iterator, device):\n    with torch.no_grad():\n        for x,_ in test_iterator:\n            x = x.view(x.shape[0], -1).to(device)\n            out = model(x)\n            display_images(None, out, 5)\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fn(model, test_iterator, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_images(None, model.Encoder[0].weight, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **SPARSE AUTOENCODER**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Sparse_AE(nn.Module):\n    def __init__(self, config):\n        super(Sparse_AE, self).__init__()\n        self.Encoder = nn.Sequential(\n            nn.Linear(config['embedding_size'], config['hidden_size']),\n            nn.ReLU(inplace=True),\n            nn.Linear(config['hidden_size'], config['hidden_size1']),\n            nn.ReLU(inplace=True),\n            nn.Linear(config['hidden_size1'], config['hidden_size2']),\n            nn.ReLU(inplace=True),\n            nn.Linear(config['hidden_size2'], config['hidden_size3']),\n            nn.ReLU(inplace=True),\n        )\n        self.Decoder = nn.Sequential(\n             nn.Linear(config['hidden_size3'], config['hidden_size2']),\n            nn.ReLU(inplace=True),\n            nn.Linear(config['hidden_size2'], config['hidden_size1']),\n            nn.ReLU(inplace=True),\n            nn.Linear(config['hidden_size1'], config['hidden_size']),\n            nn.ReLU(inplace=True),\n            nn.Linear(config['hidden_size'], config['embedding_size']),\n            nn.LeakyReLU(0.1))\n        \n    def forward(self, x):\n        z = self.Encoder(x)\n        out = self.Decoder(z)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sparse_loss(model, images):\n    loss = 0\n    values = images\n    for i in range(4):\n        fc_layer = list(model.Encoder.children())[2 * i]\n        relu = list(model.Encoder.children())[2 * i + 1]\n        values = relu(fc_layer(values))\n        loss += torch.mean(torch.abs(values))\n    for i in range(4-1):\n        fc_layer = list(model.Decoder.children())[2 * i]\n        relu = list(model.Decoder.children())[2 * i + 1]\n        values = relu(fc_layer(values))\n        loss += torch.mean(torch.abs(values))\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sparse_criterion(model, images, y_pred, reg_param):\n    loss = nn.MSELoss()\n    loss1 = loss(y_pred, images)\n    loss2 = sparse_loss(model, images)\n\n    return loss1 + reg_param*loss2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_func(optimizer , criterion, train_data, model, device, reg_param=0.001):\n    model.train()\n    \n    loss_train = []\n    model.to(device)\n    for (x,_) in train_data:\n        x = x.to(device)\n        x = x.view(x.shape[0], -1)\n        \n        out = model(x)\n        \n        loss = criterion(model, x, out, reg_param)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        optimizer.zero_grad()\n        \n        loss_train.append(loss.item())\n        \n    return loss_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def valid_func(criterion, valid_data, model, device, reg_param=0.001):\n    model.eval()\n    \n    valid_loss = []\n    model.to(device)\n    with torch.no_grad():\n        for (x,_) in valid_data:\n            x = x.to(device)\n            x = x.view(x.shape[0], -1)\n            \n            out = model(x)\n\n            loss = criterion(model, x, out, reg_param)\n\n            valid_loss.append(loss.item())\n        \n    return valid_loss\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nlearning_rate = 1e-3\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = Sparse_AE(config)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nmodel_children = list(model.children())\n\nfor epoch in range(epochs):\n    loss_train = train_func(optimizer, sparse_criterion, train_iterator, model, device)\n    print(\"Epoch: {} || Loss: {}\".format(epoch, (np.sum(loss_train)/len(loss_train))))\n    valid_loss = valid_func(sparse_criterion, valid_iterator, model, device)\n    print(\"Epoch: {} || Validation Loss: {}\".format(epoch, (np.sum(valid_loss)/len(valid_loss))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.Encoder[4].weight.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_images(None, model.Encoder[0].weight, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fn(model, test_iterator, device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VARIATIONAL-AUTOENCODER"},{"metadata":{"trusted":true},"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, config):\n        super(VAE, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(config[\"embedding_size\"],config[\"hidden_size\"]),#784, 625\n            nn.ReLU(),\n            nn.Linear(config[\"hidden_size\"],config[\"hidden_size1\"]),#625, 50\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(config['hidden_size2'], config[\"hidden_size\"]),#25 , 625\n            nn.ReLU(),\n            nn.Linear(config[\"hidden_size\"], config[\"embedding_size\"]),#625, 784\n            nn.Tanh()\n        )\n        \n        self.config = config\n    \n    def reparameterise(self, mu, logvar):\n        #print(self.training)\n        if self.training:\n            std = logvar.mul(0.5).exp_()\n            eps = std.data.new(std.size()).normal_()\n            return eps.mul(std).add_(mu)#will make the sphere centerd in mu(mean) and have a radius of std\n        else:\n            return mu\n        \n    def forward(self, x):\n        out = self.encoder(x.view(-1, config['embedding_size'])).view(-1, 2, self.config['hidden_size2'])\n        mean = out[:,0,:]\n        logvar = out[:,1,:]\n        z = self.reparameterise(mean, logvar)\n        return self.decoder(z), mean, logvar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_function(x_hat, x, mu, logvar):\n    MSE = F.mse_loss(\n        x_hat, x.view(-1, configVAE['embedding_size']), reduction='sum'\n    )\n    KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n    \n    #KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n\n    return MSE + KLD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_func(optimizer , criterion, train_data, model, device, reg_param=0.001):\n    model.train()\n    \n    loss_train = []\n    model.to(device)\n    for (x,_) in train_data:\n        x = x.to(device)\n        x = x.view(x.shape[0], -1)\n        \n        out, mean, logvar = model(x)\n        \n        #print(out, x)\n        loss = loss_function(out, x, mean, logvar)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        optimizer.zero_grad()\n        \n        loss_train.append(loss.item())\n        \n    return loss_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def valid_func(criterion, valid_data, model, device, reg_param=0.001):\n    model.eval()\n    \n    valid_loss = []\n    model.to(device)\n    means, logvars, labels = list(), list(), list()\n    with torch.no_grad():\n        for (x,y) in valid_data:\n            x = x.to(device)\n            x = x.view(x.shape[0], -1)\n\n            out, mean, logvar = model(x)\n            \n            loss = loss_function(out, x, mean, logvar)\n\n            valid_loss.append(loss.item())\n            \n            means.append(mean.detach())\n            logvars.append(logvar.detach())\n            labels.append(y.detach())\n        \n    return valid_loss, means, logvars, labels\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_iterator.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nlearning_rate = 1e-3\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = VAE(configVAE)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nmodel_children = list(model.children())\ncodes = {'means':list(), 'logvars':list(), 'y':list()}\nfor epoch in range(epochs):\n    loss_train = train_func(optimizer, loss_function, train_iterator, model, device)\n    print(\"Epoch: {} || Loss: {}\".format(epoch, (np.sum(loss_train)/len(train_iterator.dataset))))\n    valid_loss, means, logvars, labels = valid_func(loss_function, valid_iterator, model, device)\n    codes['means'].append(torch.cat(means))\n    codes['logvars'].append(torch.cat(logvars))\n    codes['y'].append(torch.cat(labels))\n    print(\"Epoch: {} || Validation Loss: {}\".format(epoch, (np.sum(valid_loss)/len(valid_iterator.dataset))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_images(None, model.encoder[0].weight, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 16\nz = torch.randn((N, configVAE['hidden_size2'])).to(device)\nsample = model.decoder(z)\ndisplay_images(None, sample, N // 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Perform an interpolation between input A and B, in N steps\n\nN = 16\ncode = torch.Tensor(N, 2).to(device)\nsample = torch.Tensor(N, 28, 28).to(device)\nfor i in range(N):\n    code[i] = i / (N - 1) * codes['means'][3][B].data + (1 - i / (N - 1) ) * codes['means'][3][A].data\n    # sample[i] = i / (N - 1) * x[B].data + (1 - i / (N - 1) ) * x[A].data\nsample = model.decoder(code)\ndisplay_images(None, sample, N // 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, Y, E = list(), list(), list()  # input, classes, embeddings\nN = 1000  # samples per epoch\nepochs = (0, 50, 99)\nfor epoch in epochs:\n    X.append(codes['means'][epoch][:N])\n    E.append(TSNE(n_components=2).fit_transform(X[-1]))\n    Y.append(codes['y'][epoch][:N])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, a = plt.subplots(ncols=3)\nfor i, e in enumerate(epochs):\n    s = a[i].scatter(E[i][:,0], E[i][:,1], c=Y[i], cmap='tab10')\n    a[i].grid(False)\n    a[i].set_title(f'Epoch {e}')\n    a[i].axis('equal')\nf.colorbar(s, ax=a[:], ticks=np.arange(10), boundaries=np.arange(11) - .5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}